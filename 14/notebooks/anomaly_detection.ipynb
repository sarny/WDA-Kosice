{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detekcia anomálií a outlierov\n",
    "\n",
    "Outliery a anomálie je možné hľadať viacerými spôsobmi.\n",
    "\n",
    "Outliery je jednoduché hľadať napr. pomocou rôznych vizualizácií, ak hľadáme outliery v rámci jednotlivých atribútov alebo v rámci kombinácie hodnôt malého počtu atribútov. \n",
    "\n",
    "Z jednoduchých vizualizačných techník pre detekciu outlierov môžeme použiť:\n",
    "\n",
    "### Úloha 13.7:\n",
    "\n",
    "Ktoré vizualizačné techniky podporované knižnicou Seaborn môžeme priamo použiť pre detekciu outlierov?\n",
    "Použite zvolené techniky pre detekciu outlierov v rámci datasetu Titanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"../data/titanic-processed.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "g = sns.distplot(titanic[\"fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "g = sns.boxplot(x=\"pclass\", y=\"fare\", data=titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "g = sns.scatterplot(x=\"pclass\", y=\"fare\", data=titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okrem takýchto vizualizácií je možné outliery detegovať pomocou zhlukovacích algoritmov. V takom prípade je vhodné použiť takú metódu, ktorá nám deteguje málo-početné zhluky, ktoré sú vzdialené od štandardných príkladov. Na detekciu môžeme teda použiť metódy založené na hustote (ako napr. DBSCAN), kde nastavíme faktor vzdialenosti bodov patriacich do zhluku tak, aby sme odlíšili všetky štandardné príklady od tých vzdialených, ktoré považujeme za outliery. \n",
    "\n",
    "Na príklade datasetu Titanic si demonštrujeme použitie metódy DBSCAN pre detekciu outlierov z pohľadu atribútov `age` a `fare`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predspracujeme dáta rovnako ako v píkladoch z predoškých cvičení:\n",
    "# - odstránime atribúty, ktoré nebudeme používať (napr. duplicitné)\n",
    "# - binárne a ordinálne atribúty namapujeme na indexy\n",
    "# - kategorické atribúty bez usporiadania transformujeme pomocou One Hot prístupu\n",
    "\n",
    "titanic = titanic.drop(columns=['cabin','deck','ticket','title'])\n",
    "titanic['sex'] = titanic['sex'].map({\"male\": 0, \"female\": 1})\n",
    "titanic['has_family'] = titanic['has_family'].map({False: 0, True: 1})\n",
    "titanic['fare_ordinal'] = titanic['fare_ordinal'].map({\"normal\": 0, \"more expensive\": 1, \"most expensive\": 2}) \n",
    "titanic['age_ordinal'] = titanic['age_ordinal'].map({\"child\": 0, \"young\": 1, \"adult\": 2, \"old\": 3}) \n",
    "titanic = pd.get_dummies(titanic, columns=['embarked', 'title_short'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natrénujeme model DBSCAN s definovanou hodnotou parametra `eps`. Skúsime nájsť správnu hodnotu parametra tak, aby vhodne separovala príklady do zhlukov - cieľom je \"oddeliť\" ouliery od štandardných príkladov. \n",
    "\n",
    "Výsledky potom môžeme vykresliť pomocou Seaborn knižnice a jej bodového grafu (scatter plot). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=100) # inicializujeme DBSCAN model pre definovanú hodnotu minimálnej vzdialenosti\n",
    "\n",
    "labels = dbscan.fit_predict(titanic) # natrénujeme model na vstupných dátach\n",
    "\n",
    "g = sns.scatterplot(x='age', y='fare', hue=labels, data=titanic) # vykreslíme bodový graf, farebne rozlíšený podľa zhlukov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okrem jednoduchých vizualizačných techník a nízko-rozmerných dát vieme použiť zhlukovanie na detekciu anomálií v dátach. Obvykle je tieto metódy dobré použiť aj tam, kde sa jedná o predikčnú úlohu s veľmi nevybalansovaným cieľovým atribútom - minoritnú triedu tak môžeme \"odhaliť\" pomocou zhlukovania.\n",
    "\n",
    "Ako príklad si ukážeme ako detegovať podozrivé transakcie v dátach popisujúcich transakcie vykonané pomocou kreditných kariet. \n",
    "\n",
    "Pochopenie a interpretácia dát je obtiažna - jedná sa o transformované príznaky, ktoré sú zakódované, vieme len, že sa jedná o atribúty platiteľa a samotnej platby. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize # importujeme používané knižnice\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data=pd.read_csv(\"../data/creditcard.csv\") # načítame dáta do dátového rámca zo súboru\n",
    "data.head() # vypíšeme na obrazovku prvých 5 záznamov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozrieme sa na distribúciu cieľového atribútu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(x='Class', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset transformujeme rovnako ako pri predikčných úlohách - odseparujeme si maticu príznakov a vektor hodnôt cieľového atribútu `Class`. Ten môžeme potom použiť pre verifikáciu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data.drop([\"Time\",\"Class\"],axis=1)\n",
    "labels=pd.DataFrame(data[[\"Class\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dátový rámec s maticou príznakov normalizujeme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "features=normalize(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz skúsime natrénovať zhlukovací model. Cheme natrénovať model tak, aby nám oddelil vhodným spôsobom triedy predstavujúce anomálie od majoritných transakcií. Porovnáme potom výsledky zhlukovania so skutočnými hodnotami, ktoré uchovávame vo vektore hodnôt cieľového atribútu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#kmeans=KMeans(n_clusters=2, max_iter=300)\n",
    "#kmeans.fit(features)\n",
    "#y_kmeans=kmeans.predict(features)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5)\n",
    "y_dbscan = dbscan.fit_predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výsledky zhlukovania môžeme vyjadriť aj početnosťou zhlukov. Tá nám dá aspoň približný odhad kvality zhlukovacieho modelu (pomer príkladov v zhlukoch). Samozjreme, nehovorí ešte nič o tom, či príklady v jednotlivých zhlukoch skutočne zodpovedajú aj priradeniu tried. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters, counts = np.unique(y_kmeans, return_counts=True) # pomocou funkcie unique identifikujeme rôzne hodnoty a vrátime aj ich počty\n",
    "#print(np.asarray((clusters, counts))) \n",
    "\n",
    "clusters, counts = np.unique(y_dbscan, return_counts=True) # pomocou funkcie unique identifikujeme rôzne hodnoty a vrátime aj ich počty\n",
    "print(np.asarray((clusters, counts))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(labels,y_kmeans))\n",
    "\n",
    "y_dbscan[y_dbscan == -1] = 1\n",
    "print(confusion_matrix(labels == 1,y_dbscan == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraud = data[data['Class']==1]\n",
    "Valid = data[data['Class']==0]\n",
    "\n",
    "outlier_fraction = len(Fraud)/float(len(Valid))\n",
    "print(outlier_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre hľadanie outlierov môžeme použiť aj metódu Local Outlier Factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor # importujeme knižnice\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=40, metric='euclidean', contamination = outlier_fraction) # vytvoríme model, počíta sa hustota v okolí každého príkladu (počet susedov)\n",
    "y_lof = lof.fit_predict(features) # natrénujeme model\n",
    "#scores_prediction = lof.negative_outlier_factor_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lof[y_lof == 1] = 0\n",
    "y_lof[y_lof == -1] = 1\n",
    "\n",
    "print(confusion_matrix(labels,y_lof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
