{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zhlukovanie - Vyhodnotenie a interpretácia zhlukov - príklad 1\n",
    "\n",
    "Nasledujúci príklad demonštruje zhlukovanie nákupných dát ako v minulotýždňovom príklade. \n",
    "\n",
    "Tentoraz sa zameriame na iné kritériá pre vyhodnotenie kvality a kompaktnosti zhlukov a ich interpretáciu nie pomocou vizualizácií, ale pomocou rozhodovacích stromov. \n",
    "\n",
    "Najprv si importujeme potrebné knižnice pre prácu s dátovými rámcami, poľami a pre vykresľovanie grafov. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do dátového rámca načítame vstupné dáta zo súboru. Vypíšeme prvých 5 záznamov.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/wholesale.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rovnako ako v predošlom cvičení transformujeme dáta pomocou One Hot Encoderu (oba atribúty obsahujúce kategorické dáta) a 5 prvých záznamov transformovaného datasetu vypíšeme na obrazovku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['Channel', 'Region']) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keďže budeme vytvárať K-Means model, tak numerické atribúty normalizujeme použitím MinMaxScaler-u. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # importujeme MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() # Inicializujeme transformátor\n",
    "scaler.fit(data) # aplikujeme ho na vstupné dáta\n",
    "\n",
    "# po aplikovaní scaleru budeme mať výstup vo forme numpy poľa\n",
    "# to môžeme - ale nemusíme - naspať transformovať do pandas rámca (ak chceme ešte robiť nejaké predspracovanie)\n",
    "# funkcie pre trénovanie modelov potom vedia pracovať aj s pandas aj s numpy\n",
    "\n",
    "# data_norm = scaler.transform(data)\n",
    "data_norm = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kritérium Silhouette \n",
    "\n",
    "Okrem sumy štvorocov vzdialeností od reprezentanta zhluku môžeme použiť viacero iných metrík, ktoré definujú kvalitu jednotlivých zhlukov. Tie má zmysel použiť:\n",
    "* tam, kde nepoužívame metódy, ktoré vytvárajú reprezentantov zhlukov\n",
    "* vtedy, ak chceme použiť iné kritérium, ako používa samotný algorimtus \n",
    "\n",
    "Jedným z takýchto kritérií je index Silhouette. Ten udáva koeficient, vypočítaný pre každý príklad a spriemernený pre celú dátovú množinu. Koeficient kombinuje priemernú hodnotu metriky vnútro-zhlukovej vzdialenosti s priemernou vzdialenosťou k najbližšiemu zhluku. Koeficient nadobúda hodnoty od 0 a 1 (pre každý príklad). Hodnota blízka nule znamená, že príklad je pravdepodobne zaradený do nesprávneho zhluku a hodnoty bližšie k 1 vyjadrujú, že príklad je regulérnym prvkom predikovaného zhluku a dobre odlíšiteľný od ostatných. Koeficient Silhouette v scikit-learn potom vypočítava priemernú hodnotu pre všetky príklady. To potom umožňuje porovnať viacero zhlukovacích modelov (s rôznymi počtami zhlukov) navzájom. \n",
    "\n",
    "Podobne ako v prípade hľadania správnej hodnoty zhlukov pomocou sumy štvorcov vzdialeností, môžeme v cykle povytvárať viacero modelov, ktoré prostredníctvom tohoto kritéria evaluujeme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans # importujeme knižnicu pre KMeans\n",
    "from sklearn.metrics import silhouette_score # importujeme funkciu pre výpočet Silhouette\n",
    "\n",
    "# použijeme Silhouette score pre počet zhlukov\n",
    "# môžeme potom porovnať ideálne počty zhlukov pre rôzne kritériá\n",
    "\n",
    "K = range(2,10) # vygenerujeme pole parametrov (počet zhlukov)\n",
    "\n",
    "results = [] \n",
    "\n",
    "# v cykle vytvoríme pre každú hodnotu parametra zhlukovací model, počet zhlukov zodpovedá hodnote iterátora\n",
    "\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters = k)\n",
    "    model.fit(data_norm)\n",
    "    predictions = model.predict(data_norm) # pre výpočet silhouette priradíme príklady zo vstupných dát do zhlukov\n",
    "    results.append(silhouette_score(data_norm, predictions)) # vypočítame skóre a priradíme ho do znoznamu, v ktorom budeme ukladať všetky skóre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# výsledky môžeme vypísať na obrazovku\n",
    "# zoznam obsahuje Silhouette skóre pre parametre, v poradí, v akom boli vytvárané\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ak chceme, skóre Silhouette vieme vizualizovať rovnakým spôsobom ako v prípade sumy štvorcov vzdialeností od centroidu. \n",
    "\n",
    "### Úloha 13.1:\n",
    "\n",
    "Použite matplotlib rovnako ako v úlohách z predošlého cvičenia na vykreslenie závislosti počtu zhlukov od Silhouette skóre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz môžeme natrénovať model s najlepšim skóre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=6) # vytvoríme model pre stanovený počet zhlukov\n",
    "model.fit(data_norm) # naučíme na trénovacej množine\n",
    "\n",
    "labels = model.predict(data_norm) # vstupné dáta zatriedime do zhlukov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na príslušnosť príkladov do zhlukov sa môžeme pozrieť vypísaním ich predikcií\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstatnou informáciou môže byť aj početnosť jednotlivých zhlukov v rámci vstupných dát. Tú si môžeme jednoducho spočítať z `labels` a to tak, že spočítame počty výskytov rôznych prvkov poľa výsledkov zhlukovania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, counts = np.unique(labels, return_counts=True) # pomocou funkcie unique identifikujeme rôzne hodnoty a vrátime aj ich počty\n",
    "print(np.asarray((clusters, counts))) # aby sme \"krajšie\" naformátovali výstup, spojíme ich do numpy poľa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretácia zhlukov pomocou klasifikátorov\n",
    "\n",
    "Jednou z možností (okrem skúmania hodnôt atribútov atď.), ako interpretovať výsledné zhluky je postaviť nad danými zhlukmi klasifikačné modely, ktoré umožnia príklady patriace do daného zhluku nejakým spôsobom popísať.\n",
    "\n",
    "V takomto prípade je proces nasledovný - zhlukovaním si vlastne z pohľadu klasifikácie \"vygenerujeme\" cieľový atribút. Jednotlivé zhluky potom v podstate predstavujú jeho jednotlivé hodnoty - triedy. K vstupným dátam môžeme teda priradiť \"cieľový atribút\", ktorý ale teraz vyjadruje príslušnosť príkladu do konkrétneho zhluku. Nad takýmito dátami teda môžeme vytvoriť klasifikačný model - ideálne taký, ktorý je dobre reprezetovateľný a pochopiteľný, keďže našim cieľom je vytvorené zhluky pochopiť a porozumieť im, ideálne aj popísať napr. pomocou kombinácie hodnôt atribútov.\n",
    "\n",
    "Keď použijeme vstupné dáta (`data`) a vektor príslušnosti príkladov do zhlukov (`labels`), vytvoríme tak v podstate dvojicu matica príznakov a vektor hodnôt cieľového atribútu, ktoré používame v klasifikácii. Dáta sú potom pripravené v takej podobe, že ich môžeme použiť na trénovanie klasifikačných modelov. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dátový rámec data v podstate zodpovedá matici príznakov\n",
    "# stĺpec hodnôt cieľového atribútu zodpovedá vektoru hodnôt cieľového atribútu\n",
    "\n",
    "X_train = data\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úloha 13.2:\n",
    "\n",
    "Aký klasifikátor je potrebné natrénovať, na takýchto dátach, aby sme vedeli získať štruktúru vhodnú pre popis zhlukov? Aké znalosti z takéhoto modelu a v akej forme potom môžeme získať?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úloha 13.3.:\n",
    "\n",
    "Natrénujte vhodne zvolený typ modelu na vstupných dátach. V prípade potreby ešte dodatočne predspracujte dáta. Zvoľte metódu pre nájdenie parametrov, alebo parametre modelu odhadnite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úloha 13.4:\n",
    "\n",
    "Natrénujte model s vhodnými parametrami na vstupných dátach a zobrazte preň `confusion_matrix`. Porovnajte výslednú maticu s výsledkami početnosti jednotlivých zhlukov.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úloha 13.5:\n",
    "\n",
    "Použite kód z príkladov z predchádzajúcich cvičení a pokúste sa vizualizovať vytvorený model. Viete pomocou znalostí, ktoré z jeho štruktúry odvodíte popísať jednotlivé triedy, resp. zhluky?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "with open(\"file.txt\", \"w\") as f:\n",
    "    f = tree.export_graphviz(dtree, feature_names=X_train.columns.values, class_names=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
